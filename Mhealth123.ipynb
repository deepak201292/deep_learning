{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mhealth123.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XACyfE-X7QD"
      },
      "source": [
        "\n",
        "#@title Importing required packages\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m44dyAikYKRw"
      },
      "source": [
        "#@title Fetching PAMAP\n",
        "# PAMAP\n",
        "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00231/PAMAP2_Dataset.zip\n",
        "! unzip PAMAP2_Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFoO9C-uYLld"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is9y86dwY5TD"
      },
      "source": [
        "#@title Fetching MHealth\n",
        "# MHEALTH\n",
        "! wget http://archive.ics.uci.edu/ml/machine-learning-databases/00319/MHEALTHDATASET.zip\n",
        "! unzip MHEALTHDATASET.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr_A8hCHY-6L"
      },
      "source": [
        "#@title Packages\n",
        "!apt install poppler-utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twnfvG--ZJMO"
      },
      "source": [
        "\n",
        "#@title MHealth Dataset Readme\n",
        "! cat MHEALTHDATASET/README.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrfXm8xLZRMC"
      },
      "source": [
        "\n",
        "#@title -\n",
        "\n",
        "!pdftotext PAMAP2_Dataset/readme.pdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dWUYp_iZf7B"
      },
      "source": [
        "#@title PAMAP2 Dataset Readme\n",
        "!cat PAMAP2_Dataset/readme.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3lK9C2jZkeW"
      },
      "source": [
        "#@title Inspecting MHealth log File\n",
        "!head -n 10 MHEALTHDATASET/mHealth_subject1.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98PVPB12ZulF"
      },
      "source": [
        "#@title Inspecting PAMAP2 file\n",
        "!head -n 10 PAMAP2_Dataset/Protocol/subject101.dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txAcmHt9aQPJ"
      },
      "source": [
        "\n",
        "#@title MHealth Files List\n",
        "for i in os.listdir('MHEALTHDATASET/'):\n",
        "  if not re.search('README', i):\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n8Q1hYlaV1E"
      },
      "source": [
        "#@title Converting one subject to DataFrame\n",
        "mHealth = pd.read_csv('MHEALTHDATASET/mHealth_subject3.log', header=None, sep='\\t').loc[:, [5,6,7,8,9,10,14,15,16,17,18,19, 23]].rename(columns={5:\"alX\", 6:\"alY\", 7:\"alZ\", 8:\"glX\", 9:\"glY\", 10:\"glZ\", 14:\"arX\",15:\"arY\", 16:\"arZ\", 17:\"grX\", 18:\"grY\", 19:\"grZ\", 23:\"Output\"})\n",
        "mHealth.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrO5hRSba6DD"
      },
      "source": [
        "sns.pairplot(mHealth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP1JNfwVbKbS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si4NycPKbyd1"
      },
      "source": [
        "EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZiN0Azyb1eN"
      },
      "source": [
        "#@title Describe MHealth Dataset One Subject\n",
        "mHealth.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQxvt2F3b7EU"
      },
      "source": [
        "#@title Describe MHealth for all\n",
        "all = mHealth[mHealth[\"Output\"] == 14].copy()\n",
        "\n",
        "for i in os.listdir('MHEALTHDATASET/'):\n",
        "  if not re.search('README', i):\n",
        "    all = all.append(pd.read_csv('MHEALTHDATASET/'+i, header=None, sep='\\t').loc[:, [5,6,7,8,9,10,14,15,16,17,18,19, 23]].rename(columns={5:\"alX\", 6:\"alY\", 7:\"alZ\", 8:\"glX\", 9:\"glY\", 10:\"glZ\", 14:\"arX\",15:\"arY\", 16:\"arZ\", 17:\"grX\", 18:\"grY\", 19:\"grZ\", 23:\"Output\"}))\n",
        "\n",
        "\n",
        "description = all.describe()\n",
        "\n",
        "description.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubqaLYb4cBlZ"
      },
      "source": [
        "description[\"alX\"][\"max\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LShuBIYrcruo"
      },
      "source": [
        "mhealth dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls4hbccfdOPB"
      },
      "source": [
        "#@title Size of dataset for various subjects\n",
        "for i in os.listdir('MHEALTHDATASET/'):\n",
        "  if not re.search('README', i):\n",
        "    print(pd.read_csv('MHEALTHDATASET/'+i, header=None, sep='\\t').loc[:, [5,6,7,8,9,10,14,15,16,17,18,19, 23]].rename(columns={5:\"alX\", 6:\"alY\", 7:\"alZ\", 8:\"glX\", 9:\"glY\", 10:\"glZ\", 14:\"arX\",15:\"arY\", 16:\"arZ\", 17:\"grX\", 18:\"grY\", 19:\"grZ\", 23:\"Output\"}).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm46Fu4Pdc06"
      },
      "source": [
        "temp.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaZ4XR-bd0IM"
      },
      "source": [
        "#@title Importing and preprocessing dataset\n",
        "SAMPLES_PER_ACTIVITY=119  #@param { \"type\": \"integer\" }\n",
        "\n",
        "Activities = [\n",
        "    \"Nothing\",\n",
        "    \"Standing\",\n",
        "    \"Sitting and Relaxing\",\n",
        "    \"Lying Down\",\n",
        "    \"Walking\",\n",
        "    \"Climbing Stairs\",\n",
        "    \"Waist bends forward\",\n",
        "    \"Frontal Elevation of Arms\",\n",
        "    \"Knees Bending (Crouching)\",\n",
        "    \"Cycling\",\n",
        "    \"Jogging\",\n",
        "    \"Running\",\n",
        "    \"Jump Front & Back\"\n",
        "    ]\n",
        "\n",
        "\n",
        "NUM_ACTIVITY=len(Activities)\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "FEATURES=[\"alX\", \"alY\", \"alZ\", \"glX\", \"glY\", \"glZ\", \"arX\", \"arY\", \"arZ\", \"grX\", \"grY\", \"grZ\"]\n",
        "ONE_HOT_ENCODED_ACTIVITY = np.eye(NUM_ACTIVITY)\n",
        "for i in os.listdir('MHEALTHDATASET/'):\n",
        "  if not re.search('README', i):\n",
        "    temp = pd.read_csv('MHEALTHDATASET/'+i, header=None, sep='\\t').loc[:, [5,6,7,8,9,10,14,15,16,17,18,19, 23]].rename(columns={5:\"alX\", 6:\"alY\", 7:\"alZ\", 8:\"glX\", 9:\"glY\", 10:\"glZ\", 14:\"arX\",15:\"arY\", 16:\"arZ\", 17:\"grX\", 18:\"grY\", 19:\"grZ\", 23:\"Output\"})\n",
        "    for j in range(NUM_ACTIVITY):\n",
        "        output = ONE_HOT_ENCODED_ACTIVITY[j]\n",
        "        df =np.array(temp[temp[\"Output\"] == j].copy())\n",
        "        num_recordings = int(df.shape[0]/SAMPLES_PER_ACTIVITY)\n",
        "        print(f\"\\tThere are {num_recordings} recordings of the {Activities[j]} activity.\")\n",
        "        for k in range(num_recordings):\n",
        "          tensor = []\n",
        "          for l in range(SAMPLES_PER_ACTIVITY):\n",
        "            index = k * SAMPLES_PER_ACTIVITY + l\n",
        "\n",
        "            tensori = []\n",
        "            for m,feature in enumerate(FEATURES):\n",
        "              tensori.append(df[index,m] + (description[feature][\"mean\"]+3*description[feature][\"std\"]) / (3*description[feature][\"std\"]))\n",
        "            \n",
        "            tensor.append(tensori)\n",
        "          X.append(tensor)\n",
        "          Y.append(output)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "\n",
        "print(\"Data set parsing and preparation complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onGHe3UtedN4"
      },
      "source": [
        "X = X.reshape((X.shape[0], X.shape[1], X.shape[2], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oo506tZfbSA"
      },
      "source": [
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjcEl056ffaK"
      },
      "source": [
        "\n",
        "from tensorflow.keras import layers, Sequential, Input\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVuSRjDIfxNB"
      },
      "source": [
        "input_shape=X.shape[1:]\n",
        "\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAnMGlnUf1AS"
      },
      "source": [
        "grumodel = Sequential(\n",
        "    [\n",
        "     Input(shape=input_shape),\n",
        "     layers.Conv2D(64, (3,3)),\n",
        "     layers.MaxPool2D((2,2)),\n",
        "     layers.BatchNormalization(),  \n",
        "     layers.Reshape((-1, 64)),\n",
        "     layers.GRU(15),\n",
        "     layers.Dense(128, activation=\"relu\"),\n",
        "     layers.Dense(13, activation=\"sigmoid\"),\n",
        "\n",
        "    ]\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU5yvMlyf6bn"
      },
      "source": [
        "grumodel.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuoC2ff3gA2M"
      },
      "source": [
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaFRUYZJgjoC"
      },
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvavDuLRgpIY"
      },
      "source": [
        "grumodel.fit(x=X_train, \n",
        "          y=Y_train, \n",
        "          epochs=20, \n",
        "          validation_data=(X_test, Y_test), \n",
        "          callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTwIskxQgtGr"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duNxYAHJg-36"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}